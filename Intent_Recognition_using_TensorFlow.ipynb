{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjtKK0Ak7mnZLN+/BJlrGK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nawapon19/NLP-Practice/blob/main/Intent_Recognition_using_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intent Recognition using TensorFlow**"
      ],
      "metadata": {
        "id": "TeHnc0LuYXcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intent recognition is a method of natural language processing, which deals with determining intent of a given sentence, or in simple terms “what the sentence means”. It is commonly used in chatbots, virtual assistants, and other conversational AI systems to understand user requests and provide appropriate responses."
      ],
      "metadata": {
        "id": "y49PqJV2Ynhl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Jfy7Qw8Olb8J"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries and modules\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset from json file\n",
        "with open('Intent.json', 'r') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "# inspect dataset\n",
        "print(data.keys()) # elements in json file\n",
        "print(type(data['intents'])) # type of value in 'intents' dict\n",
        "print(len(data['intents'])) # total number of examples\n",
        "print(data['intents'][0].keys()) # elements in each example\n",
        "data['intents'][-1] # print the last example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F804TTbDaYTZ",
        "outputId": "449a12c9-3019-4598-88f4-2c33e5153f7e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['intents'])\n",
            "<class 'list'>\n",
            "22\n",
            "dict_keys(['intent', 'text', 'responses', 'extension', 'context', 'entityType', 'entities'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent': 'SelfAware',\n",
              " 'text': ['Can you prove you are self-aware',\n",
              "  'Can you prove you are self aware',\n",
              "  'Can you prove you have a conscious',\n",
              "  'Can you prove you are self-aware please',\n",
              "  'Can you prove you are self aware please',\n",
              "  'Can you prove you have a conscious please',\n",
              "  'prove you have a conscious'],\n",
              " 'responses': ['That is an interesting question, can you prove that you are?',\n",
              "  'That is an difficult question, can you prove that you are?',\n",
              "  'That depends, can you prove that you are?'],\n",
              " 'extension': {'function': '', 'entities': False, 'responses': []},\n",
              " 'context': {'in': '', 'out': '', 'clear': False},\n",
              " 'entityType': 'NA',\n",
              " 'entities': []}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data cleaning**"
      ],
      "metadata": {
        "id": "RBZJB_o2dJ7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function for data cleaning\n",
        "# remove all non-alphabet characters\n",
        "def clean(line):\n",
        "  cleaned_line = ''\n",
        "  for char in line:\n",
        "    if char.isalpha():\n",
        "      cleaned_line += char\n",
        "    else:\n",
        "      cleaned_line += ' '\n",
        "\n",
        "  # rearrange the line by splitting each word and join them back together with ' '\n",
        "  cleaned_line = ' '.join(cleaned_line.split())\n",
        "\n",
        "  return cleaned_line"
      ],
      "metadata": {
        "id": "UIYbbIJddBr1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean(\"I'm 27 years old now\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1JtWyCYwfW2Z",
        "outputId": "2677c9cf-89f1-4d84-db9e-997c7830f4bd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I m years old now'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**"
      ],
      "metadata": {
        "id": "sN93fLiwgxkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create list of intents\n",
        "intents = []\n",
        "unique_intents = []\n",
        "\n",
        "# create list of all text data to create a corpus\n",
        "text_input = []\n",
        "\n",
        "# create dictionary for mapping intent with appropriate response\n",
        "response_for_intent = {}\n",
        "\n",
        "for intent in data['intents']:\n",
        "  # update list of unique intents\n",
        "  if intent['intent'] not in unique_intents:\n",
        "    unique_intents.append(intent['intent'])\n",
        "  # add cleaned text to the corpus\n",
        "  for text in intent['text']:\n",
        "    text_input.append(clean(text))\n",
        "    # add intent of each text to lists of intent at the same index position\n",
        "    intents.append(intent['intent'])\n",
        "  # update intent in response dict\n",
        "  if intent['intent'] not in response_for_intent:\n",
        "    response_for_intent[intent['intent']] = []\n",
        "  # update response for intent in response dict\n",
        "  for response in intent['responses']:\n",
        "    response_for_intent[intent['intent']].append(response)"
      ],
      "metadata": {
        "id": "1tnUJcD9gaaW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Intent :\", intents[0])\n",
        "print(\"Number of Intent: \", len(intents))\n",
        "print(\"Sample Input: \", text_input[0])\n",
        "print(\"Length of text_input: \", len(text_input))\n",
        "print(\"Sample Response: \", response_for_intent[intents[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxBYhqEfk6oL",
        "outputId": "0e35329a-0326-4da8-e5c6-9a75ce53efe4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent : Greeting\n",
            "Number of Intent:  143\n",
            "Sample Input:  Hi\n",
            "Length of text_input:  143\n",
            "Sample Response:  ['Hi human, please tell me your GeniSys user', 'Hello human, please tell me your GeniSys user', 'Hola human, please tell me your GeniSys user']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization and Embedding**"
      ],
      "metadata": {
        "id": "6VjuYQMumKVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create tokenizer object and fit the text input\n",
        "# vectorize a text corpus,\n",
        "# by turning each text into a sequence of integers (each integer being the index of a token in a dictionary)\n",
        "tokenizer = Tokenizer(filters = '', oov_token = '<unk>') # <unk> unknown bucket for out of vocab words\n",
        "tokenizer.fit_on_texts(text_input)\n",
        "\n",
        "# tokenize text input and pad sequences to the same size\n",
        "sequences = tokenizer.texts_to_sequences(text_input)\n",
        "padded_sequences = pad_sequences(sequences, padding='pre')\n",
        "\n",
        "print(\"Shape of Input Sequence: \", padded_sequences.shape)\n",
        "padded_sequences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCWOs6Tnlwf7",
        "outputId": "311b1d42-b26f-4a99-f3ba-3b3566b63c09"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Input Sequence:  (143, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0, 52],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 52, 53],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 68],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 39],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 39, 53]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-pw5accoj7l",
        "outputId": "62bd50d8-ca65-4f25-fdab-e5dd220e8a70"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[52], [52, 53], [68], [39], [39, 53]]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_input[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8exQ3uKotmV",
        "outputId": "568d181c-e1d6-4e2d-bff3-9ccbb817e6c8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi', 'Hi there', 'Hola', 'Hello', 'Hello there']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_input[-5:])\n",
        "print(sequences[-5:])\n",
        "print(padded_sequences[-5:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLW5mOpio6RG",
        "outputId": "0cdc73e4-13f3-443b-953f-96451259c48d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Can you prove you have a conscious', 'Can you prove you are self aware please', 'Can you prove you are self aware please', 'Can you prove you have a conscious please', 'prove you have a conscious']\n",
            "[[11, 2, 28, 2, 66, 17, 67], [11, 2, 28, 2, 5, 50, 51, 14], [11, 2, 28, 2, 5, 50, 51, 14], [11, 2, 28, 2, 66, 17, 67, 14], [28, 2, 66, 17, 67]]\n",
            "[[ 0  0 11  2 28  2 66 17 67]\n",
            " [ 0 11  2 28  2  5 50 51 14]\n",
            " [ 0 11  2 28  2  5 50 51 14]\n",
            " [ 0 11  2 28  2 66 17 67 14]\n",
            " [ 0  0  0  0 28  2 66 17 67]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Extraction**"
      ],
      "metadata": {
        "id": "b6XTL74RqOf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural network cannot process sentences, so numerical representation of sentences have to be provided to it, this is done by doing Feature Extraction, for that we map all words with their indexes and create a matrix mapping it to its category (intent)."
      ],
      "metadata": {
        "id": "ILsMnbCXqPwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intent_to_index = {}\n",
        "categorical_target = []\n",
        "index = 0\n",
        "\n",
        "# create intent to index mapping\n",
        "for intent in intents:\n",
        "  if intent not in intent_to_index:\n",
        "    intent_to_index[intent] = index\n",
        "    index += 1\n",
        "  # create a list of intents as index numbers\n",
        "  categorical_target.append(intent_to_index[intent])\n",
        "\n",
        "num_classes = len(intent_to_index)\n",
        "print(\"Number of Intents: \", num_classes)\n",
        "\n",
        "# convert intent_to_index to index_to_intent mapping\n",
        "index_to_intent = {index: intent for intent, index in intent_to_index.items()}\n",
        "index_to_intent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehjVCvSFpTUY",
        "outputId": "13cc1b75-7831-44f1-9b52-ae6b08d32f68"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Intents:  22\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Greeting',\n",
              " 1: 'GreetingResponse',\n",
              " 2: 'CourtesyGreeting',\n",
              " 3: 'CourtesyGreetingResponse',\n",
              " 4: 'CurrentHumanQuery',\n",
              " 5: 'NameQuery',\n",
              " 6: 'RealNameQuery',\n",
              " 7: 'TimeQuery',\n",
              " 8: 'Thanks',\n",
              " 9: 'NotTalking2U',\n",
              " 10: 'UnderstandQuery',\n",
              " 11: 'Shutup',\n",
              " 12: 'Swearing',\n",
              " 13: 'GoodBye',\n",
              " 14: 'CourtesyGoodBye',\n",
              " 15: 'WhoAmI',\n",
              " 16: 'Clever',\n",
              " 17: 'Gossip',\n",
              " 18: 'Jokes',\n",
              " 19: 'PodBayDoor',\n",
              " 20: 'PodBayDoorResponse',\n",
              " 21: 'SelfAware'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One-Hot Encoding**"
      ],
      "metadata": {
        "id": "qEHCJ4rtsZb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply one-hot encoding to categorical_target\n",
        "categorical_vec = tf.keras.utils.to_categorical(categorical_target,\n",
        "                                                num_classes = num_classes,\n",
        "                                                dtype = 'int32')\n",
        "\n",
        "print(\"Shape of Ca: \", categorical_vec.shape)\n",
        "categorical_vec[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z7PvydosDzu",
        "outputId": "40a6a0a0-84c9-4c2f-f77e-d17db1345c00"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Ca:  (143, 22)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Building**"
      ],
      "metadata": {
        "id": "H4Wslb4jtGbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set parameters for the neural network model\n",
        "epochs = 100\n",
        "embed_dim = 300\n",
        "lstm_num = 50\n",
        "output_dim = categorical_vec.shape[1]\n",
        "input_dim = len(unique_intents)\n",
        "print(\"Input Dimension: {}, \\nOutput Dimension: {}\".format(input_dim, output_dim))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvPEXiP1tBgB",
        "outputId": "a33ae7e0-7c66-4553-d17f-edee014a7568"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Dimension: 22, \n",
            "Output Dimension: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A common model for intent recognition is the **recurrent neural network (RNN)** or its variant, the **long short-term memory (LSTM) network**. These networks can handle sequential data, such as sentences, effectively. We can also use pre-trained models like **BERT** or **GPT** to achieve better performance."
      ],
      "metadata": {
        "id": "jXKLCM9pt-Jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN using sequential model,\n",
        "# consist of embedding layer, lstm layer for sequence processing,\n",
        "# and two dense layer for classification\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_num, dropout = 0.1)),\n",
        "    tf.keras.layers.Dense(lstm_num, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(output_dim, activation = 'softmax')\n",
        "])\n",
        "\n",
        "# set up optimizer for the model, 'adam' with learning rate = 0.001\n",
        "optimizer = tf.keras.optimizers.Adam(lr = 0.001)\n",
        "\n",
        "# compile the model\n",
        "# use categorical crossentropy as loss function\n",
        "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpyIvXZitxzz",
        "outputId": "de73a19b-3eeb-4514-e8d0-a79af39494e0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 300)         35700     \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 100)               140400    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 22)                1122      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 182272 (712.00 KB)\n",
            "Trainable params: 182272 (712.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**"
      ],
      "metadata": {
        "id": "D103-IuNwdDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model with labeled dataset\n",
        "model.fit(padded_sequences, categorical_vec, epochs = epochs, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaslMWh6wTRY",
        "outputId": "a17049b6-0aa4-4b11-9e20-5c8042b3cb90"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0097 - accuracy: 0.9930\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 6.0095e-04 - accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0117 - accuracy: 0.9930\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 7.3844e-04 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.0081 - accuracy: 0.9930\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 9.1990e-04 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0108 - accuracy: 0.9930\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 7.9565e-04 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 7.3081e-04 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0157 - accuracy: 0.9930\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0150 - accuracy: 0.9930\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0090 - accuracy: 0.9930\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0081 - accuracy: 0.9930\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 9.7768e-04 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 9.5897e-04 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0078 - accuracy: 0.9930\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0271 - accuracy: 0.9790\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0317 - accuracy: 0.9930\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0119 - accuracy: 0.9930\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0140 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0190 - accuracy: 0.9930\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0181 - accuracy: 0.9930\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0264 - accuracy: 0.9860\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0131 - accuracy: 0.9930\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0159 - accuracy: 0.9930\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0014 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7845eed2ace0>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate**"
      ],
      "metadata": {
        "id": "Ls9ehj5WxT30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create unseen text input with labels\n",
        "# check if it works correctly\n",
        "test_text_inputs = [\"Hello\",\n",
        "                    \"my name is adam\",\n",
        "                    \"how are you?\",\n",
        "                    \"can you guess my name?\",\n",
        "                    \"Do you get me\",\n",
        "                    \"Adios\"]\n",
        "\n",
        "test_intents = [\"Greeting\",\n",
        "                 \"GreetingResponse\",\n",
        "                 \"CourtesyGreeting\",\n",
        "                 \"CurrentHumanQuery\",\n",
        "                 \"UnderstandQuery\",\n",
        "                 \"GoodBye\"]\n",
        "\n",
        "# transform test data, tokenization and vectorization\n",
        "test_sequences = tokenizer.texts_to_sequences(test_text_inputs)\n",
        "test_padded_sequences = pad_sequences(test_sequences, padding = 'pre')\n",
        "test_labels = np.array([unique_intents.index(intent) for intent in test_intents])\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes = num_classes)\n",
        "\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(test_padded_sequences, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBEj2v5XxNiy",
        "outputId": "89d3eea1-f4e8-4bb6-b2ba-b54c22e2a808"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0118 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict**"
      ],
      "metadata": {
        "id": "8HgUWyWJ3a9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function response to predict intent and give appropriate response\n",
        "def response(sentence):\n",
        "  sent_tokens = []\n",
        "  # split the input sentence into words\n",
        "  words = sentence.split()\n",
        "  # convert words to their corresponding indices\n",
        "  for word in words:\n",
        "    if word in tokenizer.word_index:\n",
        "      sent_tokens.append(tokenizer.word_index[word])\n",
        "    else:\n",
        "      # hanedle unknown words]\n",
        "      sent_tokens.append(tokenizer.word_index['<unk>'])\n",
        "\n",
        "  # tf.expand_dims -> given a tensor input, this operation inserts a dimension of\n",
        "  # length 1 at the dimension index 'axis' of input's shape.\n",
        "  sent_tokens = tf.expand_dims(sent_tokens, 0)\n",
        "\n",
        "  # predict numerical category (probs)\n",
        "  pred = model(sent_tokens)\n",
        "\n",
        "  # category to intent (index number)\n",
        "  pred_class = np.argmax(pred.numpy(), axis = 1)\n",
        "\n",
        "  # return random response to the intent and intent type\n",
        "  return random.choice(response_for_intent[index_to_intent[pred_class[0]]]), index_to_intent[pred_class[0]]"
      ],
      "metadata": {
        "id": "QuzxXlcA0cwU"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chatbots: Intent Recognition**"
      ],
      "metadata": {
        "id": "R_EpUhro7K6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a loop to take input from user\n",
        "# recognize intent and give appropriate response\n",
        "print(\"Note: Enter 'quit' to break the loop.\")\n",
        "while True:\n",
        "  query = input('You: ')\n",
        "  if query.lower() == 'quit':\n",
        "    break\n",
        "  bot_response, typ = response(query)\n",
        "  print(\"Bot: {} -- TYPE: {}\".format(bot_response, typ))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNtjhQYg7F2W",
        "outputId": "f0b77b32-3a54-4d51-99e3-bac77df063dd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: Enter 'quit' to break the loop.\n",
            "You: Hi, Who are you?\n",
            "Bot: Hello, I am great, how are you? Please tell me your GeniSys user -- TYPE: CourtesyGreeting\n",
            "\n",
            "You: can you prove you have a concious?\n",
            "Bot: That depends, can you prove that you are? -- TYPE: SelfAware\n",
            "\n",
            "You: Can you prove you are self-aware?\n",
            "Bot: That is an interesting question, can you prove that you are? -- TYPE: SelfAware\n",
            "\n",
            "You: My name is Nawapon Srikrajang.\n",
            "Bot: OK! hi <HUMAN>, what can I do for you? -- TYPE: GreetingResponse\n",
            "\n",
            "You: Tell me a joke\n",
            "Bot: What do you call cheese that isn't yours?  Nacho cheese. -- TYPE: Jokes\n",
            "\n",
            "You: Tell me ajokes\n",
            "Bot: Let me see -- TYPE: WhoAmI\n",
            "\n",
            "You: Tell me a Jokes\n",
            "Bot: 'Where are you going on holiday?' John asked Trevor. 'We're off to Thailand this year', Trevor replied. 'Oh; aren't you worried that the very hot weather might disagree with your wife?' asked John. 'It wouldn't dare', said Trevor. -- TYPE: Jokes\n",
            "\n",
            "You: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dVWxGZfX8EXN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}