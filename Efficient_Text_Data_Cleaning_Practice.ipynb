{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMx1J3fQOXkZdApwA5h92D3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nawapon19/NLP-Practice/blob/main/Efficient_Text_Data_Cleaning_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Efficient Text Data Cleaning**\n",
        "\n",
        "Learn how to work with unstructured data to be able to extract relevant information from it and make it useful."
      ],
      "metadata": {
        "id": "BNeEziJ7YILA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Steps for Data Cleaning**"
      ],
      "metadata": {
        "id": "luofsNLOZGtA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Clear out HTML characters:** A Lot of HTML entities like &apos; ,&amp; ,&lt; etc can be found in most of the data available on the web. There are two ways to get rid of these from the data:\n",
        "\n",
        "* By using specific regular expressions or\n",
        "* By using modules or packages available(htmlparser of python)"
      ],
      "metadata": {
        "id": "kF7ESeemZH_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxJ6Ab_JX9M_",
        "outputId": "175ac153-b2dd-45c0-af1d-8b9a7a65ce65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before removing HTML characters the tweet is: \n",
            " I enjoyd the event which took place yesteday &amp; I lovdddd itttt ! The link to the show is http://t.co/4ftYom0i It&#x27;s awesome you&#x27;ll luv it #HadFun #Enjoyed BFN GN\n",
            "\n",
            "After removing HTML characters the tweet is: -\n",
            "I enjoyd the event which took place yesteday & I lovdddd itttt ! The link to the show is http://t.co/4ftYom0i It's awesome you'll luv it #HadFun #Enjoyed BFN GN\n"
          ]
        }
      ],
      "source": [
        "# escape out html characters\n",
        "import html\n",
        "\n",
        "tweet = \"I enjoyd the event which took place yesteday & I lovdddd itttt ! The link to the show is http://t.co/4ftYom0i It's awesome you'll luv it #HadFun #Enjoyed BFN GN\"\n",
        "\n",
        "# convert special characters to HTML Entities\n",
        "tweet = html.escape(tweet)\n",
        "print(\"Before removing HTML characters the tweet is: \\n\", tweet)\n",
        "\n",
        "# unescape HTML Entities\n",
        "tweet = html.unescape(tweet)\n",
        "print(\"\\nAfter removing HTML characters the tweet is: -\\n{}\".format(tweet))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Encoding & Decoding Data:** It is the process of converting information from simple understandable characters to complex symbols and vice versa. There are different forms of encoding &decoding like “UTF8″,”ascii” etc. available for text data. The most common format is the UTF-8 format."
      ],
      "metadata": {
        "id": "4n6C9z1rebDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encode from UTF-8 to ascii\n",
        "encode_tweet = tweet.encode('ascii', 'ignore')\n",
        "print(\"encode_tweet = \\n{}\".format(encode_tweet))\n",
        "\n",
        "# decode from ascii to UTF-8\n",
        "decode_tweet = encode_tweet.decode(encoding = 'UTF-8')\n",
        "print(\"\\ndecode_tweet = \\n{}\".format(decode_tweet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqOCPW6MaXuT",
        "outputId": "c5c6dd25-ee1d-47f7-ef4a-20dd55a81d8a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encode_tweet = \n",
            "b\"I enjoyd the event which took place yesteday & I lovdddd itttt ! The link to the show is http://t.co/4ftYom0i It's awesome you'll luv it #HadFun #Enjoyed BFN GN\"\n",
            "\n",
            "decode_tweet = \n",
            "I enjoyd the event which took place yesteday & I lovdddd itttt ! The link to the show is http://t.co/4ftYom0i It's awesome you'll luv it #HadFun #Enjoyed BFN GN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Removing URLs, Hashtags and Styles:** These provide no relevant information and can be removed. In hashtags, only the hash sign ‘#’ will be removed.\n",
        "* use the re library to perform regular expression operations."
      ],
      "metadata": {
        "id": "Zq97g53wfT70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import re library\n",
        "import re\n",
        "\n",
        "print(\"Before removing Hasgtags, URLs and Styles the tweet is: \\n{}\".format(tweet))\n",
        "\n",
        "# remove hyperlink characters\n",
        "tweet = re.sub(r'https?:\\/\\/.\\S+', \"\", tweet)\n",
        "\n",
        "# remove hashtags\n",
        "# only removing the hash # sign from the word\n",
        "tweet = re.sub(r'#', '', tweet)\n",
        "\n",
        "# remove old style retweet text \"RT\"\n",
        "tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "\n",
        "print(\"\\nAfter removing Hasgtags, URLs and Styles the tweet is: \\n{}\".format(tweet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAB6SBabfUHG",
        "outputId": "b2bb6c08-815f-4ea4-9fe7-09e37bd83437"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before removing Hasgtags, URLs and Styles the tweet is: \n",
            "I enjoyd the event which took place yesteday & I lovdddd itttt ! The link to the show is http://t.co/4ftYom0i It's awesome you'll luv it #HadFun #Enjoyed BFN GN\n",
            "\n",
            "After removing Hasgtags, URLs and Styles the tweet is: \n",
            "I enjoyd the event which took place yesteday & I lovdddd itttt ! The link to the show is  It's awesome you'll luv it HadFun Enjoyed BFN GN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Contraction Replacement:** The text data might contain apostrophe’s used for contractions. Example- “didn’t” for “did not” etc. This can change the sense of the word or sentence. To replace these apostrophes with the standard lexicons:\n",
        "* create a mapping dictionary which consists of the value with which the word needs to be replaced and use that."
      ],
      "metadata": {
        "id": "QG8L_pDphcju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary consisting of the contraction and the actual value\n",
        "Apos_dict = {\"'s\":\" is\",\"n't\":\" not\",\"'m\":\" am\",\"'ll\":\" will\",\n",
        "           \"'d\":\" would\",\"'ve\":\" have\",\"'re\":\" are\"}\n",
        "\n",
        "print(\"Before Contraction replacement the tweet is: \\n{}\".format(tweet))\n",
        "\n",
        "# replace the contractions\n",
        "for key, value in Apos_dict.items():\n",
        "  if key in tweet:\n",
        "    tweet=tweet.replace(key, value)\n",
        "\n",
        "print(\"\\nAfter Contraction replacement the tweet is: \\n{}\".format(tweet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDHH7zdshUid",
        "outputId": "9dad6bac-71b6-4944-a86f-8c1a18606ed6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Contraction replacement the tweet is: \n",
            "I enjoyd the event which took place yesteday & I lovdddd itttt ! The link to the show is  It's awesome you'll luv it HadFun Enjoyed BFN GN\n",
            "\n",
            "After Contraction replacement the tweet is: \n",
            "I enjoyd the event which took place yesteday & I lovdddd itttt ! The link to the show is  It is awesome you will luv it HadFun Enjoyed BFN GN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Split attached words:**  Some words are joined together for example – “ForTheWin”. These need to be separated to be able to extract the meaning out of it. After splitting, it will be “For The Win”."
      ],
      "metadata": {
        "id": "y2s-mHn_i2_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "print(\"Before splitting attached words the retweet is: \\n{}\".format(tweet))\n",
        "\n",
        "# separate the words\n",
        "tweet = \" \".join([s for s in re.split(\"([A-Z][a-z]+[^A-Z]*)\", tweet) if s])\n",
        "\n",
        "print(\"\\nAfter splitting attached words the retweet is: \\n{}\".format(tweet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKO_c_lkivoF",
        "outputId": "626afc13-4ed0-41ae-aba0-a4d446bcb407"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before splitting attached words the retweet is: \n",
            "I enjoyd the event which took place yesteday & I lovdddd itttt ! The link to the show is  It is awesome you will luv it HadFun Enjoyed BFN GN\n",
            "\n",
            "After splitting attached words the retweet is: \n",
            "I enjoyd the event which took place yesteday & I lovdddd itttt !  The link to the show is   It is awesome you will luv it  Had Fun  Enjoyed  BFN GN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Convert to lower case:** Convert your text to lower case to avoid case sensitivity related issues."
      ],
      "metadata": {
        "id": "V3uPWFGdkDck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before converting to lowercase the tweet is: \\n{}\".format(tweet))\n",
        "\n",
        "# convert to lowercase\n",
        "tweet = tweet.lower()\n",
        "\n",
        "print(\"\\nAfter converting to lowercase the tweet is: \\n{}\".format(tweet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2-QYazmkCAE",
        "outputId": "15973c6e-e1c5-4e5b-a9d6-965a369ffd05"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before converting to lowercase the tweet is: \n",
            "I enjoyd the event which took place yesteday & I lovdddd itttt !  The link to the show is   It is awesome you will luv it  Had Fun  Enjoyed  BFN GN\n",
            "\n",
            "After converting to lowercase the tweet is: \n",
            "i enjoyd the event which took place yesteday & i lovdddd itttt !  the link to the show is   it is awesome you will luv it  had fun  enjoyed  bfn gn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Slang lookup:** There are many slang words which are used nowadays, and they can be found in the text data. To replace them with their meanings:\n",
        "* use a dictionary of slang words\n",
        "* or create a file consisting of the slang words\n",
        "\n",
        "Examples of slang words are:\n",
        "* sap --> as soon as possible\n",
        "* b4   --> before\n",
        "* lol  --> laugh out loud\n",
        "* luv  --> love\n",
        "* wtg  --> way to go"
      ],
      "metadata": {
        "id": "mO53lvCvkl7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect the file for slang words\n",
        "file = open(\"slang.txt\", \"r\")\n",
        "print(file.read())\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmzHUvD_mZiD",
        "outputId": "02b2bf39-ce94-4bf6-b878-198f01e2a6be"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AFAIK=As Far As I Know\n",
            "AFK=Away From Keyboard\n",
            "ASAP=As Soon As Possible\n",
            "ATK=At The Keyboard\n",
            "ATM=At The Moment\n",
            "A3=Anytime, Anywhere, Anyplace\n",
            "BAK=Back At Keyboard\n",
            "BBL=Be Back Later\n",
            "BBS=Be Back Soon\n",
            "BFN=Bye For Now\n",
            "B4N=Bye For Now\n",
            "BRB=Be Right Back\n",
            "BRT=Be Right There\n",
            "BTW=By The Way\n",
            "B4=Before\n",
            "B4N=Bye For Now\n",
            "CU=See You\n",
            "CUL8R=See You Later\n",
            "CYA=See You\n",
            "FAQ=Frequently Asked Questions\n",
            "FC=Fingers Crossed\n",
            "FWIW=For What It's Worth\n",
            "FYI=For Your Information\n",
            "GAL=Get A Life\n",
            "GG=Good Game\n",
            "GN=Good Night\n",
            "GMTA=Great Minds Think Alike\n",
            "GR8=Great!\n",
            "G9=Genius\n",
            "IC=I See\n",
            "ICQ=I Seek you (also a chat program)\n",
            "ILU=ILU: I Love You\n",
            "IMHO=In My Honest/Humble Opinion\n",
            "IMO=In My Opinion\n",
            "IOW=In Other Words\n",
            "IRL=In Real Life\n",
            "KISS=Keep It Simple, Stupid\n",
            "LDR=Long Distance Relationship\n",
            "LMAO=Laugh My A.. Off\n",
            "LOL=Laughing Out Loud\n",
            "LTNS=Long Time No See\n",
            "L8R=Later\n",
            "MTE=My Thoughts Exactly\n",
            "M8=Mate\n",
            "NRN=No Reply Necessary\n",
            "OIC=Oh I See\n",
            "PITA=Pain In The A..\n",
            "PRT=Party\n",
            "PRW=Parents Are Watching\n",
            "QPSA?\tQue Pasa?\n",
            "ROFL=Rolling On The Floor Laughing\n",
            "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
            "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
            "SK8=Skate\n",
            "STATS=Your sex and age\n",
            "ASL=Age, Sex, Location\n",
            "THX=Thank You\n",
            "TTFN=Ta-Ta For Now!\n",
            "TTYL=Talk To You Later\n",
            "U=You\n",
            "U2=You Too\n",
            "U4E=Yours For Ever\n",
            "WB=Welcome Back\n",
            "WTF=What The F...\n",
            "WTG=Way To Go!\n",
            "WUF=Where Are You From?\n",
            "W8=Wait...\n",
            "7K=Sick:-D Laugher\n",
            "TFW – That feeling when. TFW internet slang often goes in a caption to an image.\n",
            "MFW – My face when\n",
            "MRW – My reaction when\n",
            "IFYP – I feel your pain\n",
            "LOL – Laughing out loud\n",
            "TNTL – Trying not to laugh\n",
            "JK – Just kidding\n",
            "IDC – I don’t care\n",
            "ILY – I love you\n",
            "IMU – I miss you\n",
            "ADIH – Another day in hell\n",
            "IDC – I don’t care\n",
            "ZZZ – Sleeping, bored, tired\n",
            "WYWH – Wish you were here\n",
            "TIME – Tears in my eyes\n",
            "BAE – Before anyone else\n",
            "FIMH – Forever in my heart\n",
            "BSAAW – Big smile and a wink\n",
            "BWL – Bursting with laughter\n",
            "LMAO – Laughing my a** off\n",
            "BFF: Best friends forever\n",
            "CSL – Can’t stop laughing\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before slang replacement the tweet is: \\n{}\".format(tweet))\n",
        "\n",
        "# open the file slang.txt\n",
        "file = open(\"slang.txt\", \"r\")\n",
        "slang = file.read().lower()\n",
        "\n",
        "# separate each line present in the file\n",
        "slang = slang.replace('–', '=').split('\\n')\n",
        "\n",
        "# create empty lists for mapping\n",
        "slang_word = []\n",
        "meaning = []\n",
        "\n",
        "# tokenize tweet\n",
        "tweet_tokens = tweet.split()\n",
        "\n",
        "# store slang words and meaning in different lists\n",
        "for line in slang:\n",
        "  temp = line.split('=')\n",
        "  slang_word.append(temp[0])\n",
        "  meaning.append(temp[-1])\n",
        "\n",
        "# replace the slang words with meaning\n",
        "for i, word in enumerate(tweet_tokens):\n",
        "  if word in slang_word:\n",
        "    idx = slang_word.index(word) # index for mapping slang with meaning\n",
        "    tweet_tokens[i] = meaning[idx]\n",
        "\n",
        "tweet = \" \".join(tweet_tokens)\n",
        "print(\"\\nAfter slang replacement the tweet is: \\n{}\".format(tweet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKZJGsC8kgUZ",
        "outputId": "e3a6f2f6-e4ab-4f89-ec09-7226b5199dd6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before slang replacement the tweet is: \n",
            "i enjoyd the event which took place yesteday & i lovdddd itttt !  the link to the show is   it is awesome you will luv it  had fun  enjoyed  bfn gn\n",
            "\n",
            "After slang replacement the tweet is: \n",
            "i enjoyd the event which took place yesteday & i lovdddd itttt ! the link to the show is it is awesome you will luv it had fun enjoyed bye for now good night\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Standardizing and Spell Check:** There might be spelling errors in the text or it might not be in the correct format. For example – “drivng” for “driving” or “I misssss this” for “I miss this”.\n",
        "* correct these by using the autocorrect library for python"
      ],
      "metadata": {
        "id": "tSq3MO9Eqolm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install auto correct library\n",
        "!pip install autocorrect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYiCloOOpHnc",
        "outputId": "79237dbe-40ef-4688-c0e4-d3a5873d0e12"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autocorrect in /usr/local/lib/python3.10/dist-packages (2.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# itertools.groupby()\n",
        "import itertools\n",
        "for key, group in itertools.groupby(tweet):\n",
        "  print(key + \": \", list(group))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osHRlYq-rrMh",
        "outputId": "12f8f3f4-0cf3-46d2-9b78-8b6b619a4a96"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i:  ['i']\n",
            " :  [' ']\n",
            "e:  ['e']\n",
            "n:  ['n']\n",
            "j:  ['j']\n",
            "o:  ['o']\n",
            "y:  ['y']\n",
            "d:  ['d']\n",
            " :  [' ']\n",
            "t:  ['t']\n",
            "h:  ['h']\n",
            "e:  ['e']\n",
            " :  [' ']\n",
            "e:  ['e']\n",
            "v:  ['v']\n",
            "e:  ['e']\n",
            "n:  ['n']\n",
            "t:  ['t']\n",
            " :  [' ']\n",
            "w:  ['w']\n",
            "h:  ['h']\n",
            "i:  ['i']\n",
            "c:  ['c']\n",
            "h:  ['h']\n",
            " :  [' ']\n",
            "t:  ['t']\n",
            "o:  ['o', 'o']\n",
            "k:  ['k']\n",
            " :  [' ']\n",
            "p:  ['p']\n",
            "l:  ['l']\n",
            "a:  ['a']\n",
            "c:  ['c']\n",
            "e:  ['e']\n",
            " :  [' ']\n",
            "y:  ['y']\n",
            "e:  ['e']\n",
            "s:  ['s']\n",
            "t:  ['t']\n",
            "e:  ['e']\n",
            "d:  ['d']\n",
            "a:  ['a']\n",
            "y:  ['y']\n",
            " :  [' ']\n",
            "&:  ['&']\n",
            " :  [' ']\n",
            "i:  ['i']\n",
            " :  [' ']\n",
            "l:  ['l']\n",
            "o:  ['o']\n",
            "v:  ['v']\n",
            "d:  ['d', 'd', 'd', 'd']\n",
            " :  [' ']\n",
            "i:  ['i']\n",
            "t:  ['t', 't', 't', 't']\n",
            " :  [' ']\n",
            "!:  ['!']\n",
            " :  [' ']\n",
            "t:  ['t']\n",
            "h:  ['h']\n",
            "e:  ['e']\n",
            " :  [' ']\n",
            "l:  ['l']\n",
            "i:  ['i']\n",
            "n:  ['n']\n",
            "k:  ['k']\n",
            " :  [' ']\n",
            "t:  ['t']\n",
            "o:  ['o']\n",
            " :  [' ']\n",
            "t:  ['t']\n",
            "h:  ['h']\n",
            "e:  ['e']\n",
            " :  [' ']\n",
            "s:  ['s']\n",
            "h:  ['h']\n",
            "o:  ['o']\n",
            "w:  ['w']\n",
            " :  [' ']\n",
            "i:  ['i']\n",
            "s:  ['s']\n",
            " :  [' ']\n",
            "i:  ['i']\n",
            "t:  ['t']\n",
            " :  [' ']\n",
            "i:  ['i']\n",
            "s:  ['s']\n",
            " :  [' ']\n",
            "a:  ['a']\n",
            "w:  ['w']\n",
            "e:  ['e']\n",
            "s:  ['s']\n",
            "o:  ['o']\n",
            "m:  ['m']\n",
            "e:  ['e']\n",
            " :  [' ']\n",
            "y:  ['y']\n",
            "o:  ['o']\n",
            "u:  ['u']\n",
            " :  [' ']\n",
            "w:  ['w']\n",
            "i:  ['i']\n",
            "l:  ['l', 'l']\n",
            " :  [' ']\n",
            "l:  ['l']\n",
            "u:  ['u']\n",
            "v:  ['v']\n",
            " :  [' ']\n",
            "i:  ['i']\n",
            "t:  ['t']\n",
            " :  [' ']\n",
            "h:  ['h']\n",
            "a:  ['a']\n",
            "d:  ['d']\n",
            " :  [' ']\n",
            "f:  ['f']\n",
            "u:  ['u']\n",
            "n:  ['n']\n",
            " :  [' ']\n",
            "e:  ['e']\n",
            "n:  ['n']\n",
            "j:  ['j']\n",
            "o:  ['o']\n",
            "y:  ['y']\n",
            "e:  ['e']\n",
            "d:  ['d']\n",
            " :  [' ']\n",
            "b:  ['b']\n",
            "y:  ['y']\n",
            "e:  ['e']\n",
            " :  [' ']\n",
            "f:  ['f']\n",
            "o:  ['o']\n",
            "r:  ['r']\n",
            " :  [' ']\n",
            "n:  ['n']\n",
            "o:  ['o']\n",
            "w:  ['w']\n",
            " :  [' ']\n",
            "g:  ['g']\n",
            "o:  ['o', 'o']\n",
            "d:  ['d']\n",
            " :  [' ']\n",
            "n:  ['n']\n",
            "i:  ['i']\n",
            "g:  ['g']\n",
            "h:  ['h']\n",
            "t:  ['t']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before standardizing and spell check the tweet is: \\n{}\".format(tweet))\n",
        "\n",
        "# one letter in a word should not present more than twice in continuation\n",
        "tweet = ''.join(''.join(s)[0:2] for _, s in itertools.groupby(tweet))\n",
        "print(\"\\nAfter standardizing the tweet is: \\n{}\".format(tweet))\n",
        "\n",
        "# spell check\n",
        "from autocorrect import Speller\n",
        "spell = Speller(lang = 'en')\n",
        "tweet = spell(tweet)\n",
        "\n",
        "print(\"\\nAfter spell check the tweet is: \\n{}\".format(tweet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti7Hthkrq4dD",
        "outputId": "014b417f-aa84-4740-d7b5-5ca66a6c537c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before standardizing and spell check the tweet is: \n",
            "i enjoyd the event which took place yesteday & i lovdddd itttt ! the link to the show is it is awesome you will luv it had fun enjoyed bye for now good night\n",
            "\n",
            "After standardizing the tweet is: \n",
            "i enjoyd the event which took place yesteday & i lovdd itt ! the link to the show is it is awesome you will luv it had fun enjoyed bye for now good night\n",
            "\n",
            "After spell check the tweet is: \n",
            "i enjoyed the event which took place yesterday & i loved itt ! the link to the show is it is awesome you will luv it had fun enjoyed bye for now good night\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Remove Stopwords:** Stop words are the words which occur frequently in the text but add no significant meaning to it.\n",
        "* use the nltk library which consists of modules for pre-processing data. It provides a list of stop words"
      ],
      "metadata": {
        "id": "Ke_uyoAdu1H1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install nltk library\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7zjaANBslCM",
        "outputId": "22a16025-ef61-4968-a21d-02732df821d5"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# download stopwords from nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRdTfFGcvHzF",
        "outputId": "f3564623-5730-4609-97d8-8c4e08f2b87b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before removing stopwords tweet is: \\n{}\".format(tweet))\n",
        "\n",
        "# import stopwords module\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# load english stopwords list from nltk stopwords\n",
        "stopwords_eng = stopwords.words('english')\n",
        "\n",
        "# tokenize tweet\n",
        "tweet_tokens = tweet.split()\n",
        "tweet_list = []\n",
        "\n",
        "# remove stopwords\n",
        "for word in tweet_tokens:\n",
        "  if word not in stopwords_eng:\n",
        "    tweet_list.append(word)\n",
        "\n",
        "print(\"\\ntweet_list = {}\".format(tweet_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNRx-HbkvcBl",
        "outputId": "62ad571a-4249-4804-9253-11aacc31528d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before removing stopwords tweet is: \n",
            "i enjoyed the event which took place yesterday & i loved itt ! the link to the show is it is awesome you will luv it had fun enjoyed bye for now good night\n",
            "\n",
            "tweet_list = ['enjoyed', 'event', 'took', 'place', 'yesterday', '&', 'loved', 'itt', '!', 'link', 'show', 'awesome', 'luv', 'fun', 'enjoyed', 'bye', 'good', 'night']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Remove Punctuations:** Punctuations consists of !,<@#&$ etc."
      ],
      "metadata": {
        "id": "KUyF29uawslK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tweet_list be bofore cleaning = {}\".format(tweet_list))\n",
        "\n",
        "import string\n",
        "clean_tweet = []\n",
        "\n",
        "# remove puctuation\n",
        "for word in tweet_list:\n",
        "  if word not in string.punctuation:\n",
        "    clean_tweet.append(word)\n",
        "\n",
        "print(\"\\nclean_tweet = {}\".format(clean_tweet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8liKljAMwelp",
        "outputId": "1bad9fb5-3147-4bb4-ceeb-b66ebdb4c55c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet_list be bofore cleaning = ['enjoyed', 'event', 'took', 'place', 'yesterday', '&', 'loved', 'itt', '!', 'link', 'show', 'awesome', 'luv', 'fun', 'enjoyed', 'bye', 'good', 'night']\n",
            "\n",
            "clean_tweet = ['enjoyed', 'event', 'took', 'place', 'yesterday', 'loved', 'itt', 'link', 'show', 'awesome', 'luv', 'fun', 'enjoyed', 'bye', 'good', 'night']\n"
          ]
        }
      ]
    }
  ]
}